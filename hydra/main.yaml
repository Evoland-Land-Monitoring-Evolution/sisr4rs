# @package _global_

# inspired from https://github.com/ashleve/lightning-hydra-template/blob/main/configs/train.yaml

defaults:
  - _self_
  - datamodule: default.yaml
  - losses: l1_sim.yaml
  - metrics: default.yaml
  - model: carn.yaml
  - adversarial: default.yaml
  - callbacks: default.yaml
  - training_module: default.yaml
  - trainer: default.yaml
  - log_dir: default.yaml
  - loggers: default.yaml
  - location: env.yaml
  - experiment: null
# path to original working directory
# hydra hijacks working directory by changing it to the new log directory
# https://hydra.cc/docs/next/tutorials/basic/running_your_app/working_directory
# original_work_dir: ${hydra:runtime.cwd}
original_work_dir: ${location.output_folder}
log_dir: ${original_work_dir}/log_files


# Start from a checkpoint
resume_from_checkpoint : null
start_from_checkpoint : null
load_registration_checkpoint : null

# pretty print config at the start of the run using Rich library
print_config: True

# disable python warnings if they annoy you
ignore_warnings: True

# set False to skip model training
train: True

# evaluate on test set, using best model weights achieved during training
# lightning chooses best weights based on the metric specified in checkpoint callback
#test: False

# seed for random number generators in pytorch, numpy and python.random
seed: null

# default name for the experiment, determines logging folder path
# (you can overwrite this name in experiment configs)
label: "default"
name: ${model.name}_${datamodule.name}_${losses.name}

# Log level
loglevel: INFO

# Use tensor cores ?
mat_mul_precision : 'high'
